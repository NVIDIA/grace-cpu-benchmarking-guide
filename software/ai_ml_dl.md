# AI, ML, and DL Frameworks

[PyTorch](examples/pytorch-gpu.md), [TensorFlow](apps/tensorflow-gpu.md), and[TensorRT](tensorrt.md)



NVIDIA Triton™ Inference Server — An open-source inference serving software that helps standardize model deployment and execution, delivering fast and scalable AI in production