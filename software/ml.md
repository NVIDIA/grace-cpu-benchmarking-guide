# AI, ML, and DL Frameworks

TensorRT — An SDK for high-performance deep learning inference, includes a deep learning inference optimizer and runtime that delivers low latency and high throughput for inference applications

NVIDIA Triton™ Inference Server — An open-source inference serving software that helps standardize model deployment and execution, delivering fast and scalable AI in production

PyTorch — A GPU accelerated tensor computational framework. Functionality can be extended with common Python libraries such as NumPy and SciPy

TensorFlow — An open source platform for machine learning, providing comprehensive tools and libraries in a flexible architecture allowing easy deployment across a variety of platforms and devices.